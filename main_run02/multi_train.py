"""
å¤šæ¨¡å‹å¹¶è¡Œè®­ç»ƒè„šæœ¬
æ”¯æŒåŒæ—¶è®­ç»ƒå¤šä¸ªä¸åŒé…ç½®çš„æ¨¡å‹
"""

import sys
sys.path.append('/root/SAM2PATH-main')

import os
import time
import threading
from concurrent.futures import ThreadPoolExecutor
from trainer import train_model, setup_environment, print_config_summary
from config_manager import load_config, setup_config, parse_devices


def create_training_config(config_path, project, name, devices, seed=42):
    """
    åˆ›å»ºè®­ç»ƒé…ç½®
    
    Args:
        config_path: é…ç½®æ–‡ä»¶è·¯å¾„
        project: é¡¹ç›®åç§°
        name: å®éªŒåç§°
        devices: GPUè®¾å¤‡
        seed: éšæœºç§å­
        
    Returns:
        cfg: é…ç½®å¯¹è±¡
    """
    # åŠ è½½åŸºç¡€é…ç½®
    cfg = load_config(config_path)
    
    # è®¾ç½®å‚æ•°
    cfg["project"] = project
    cfg["name"] = name
    cfg["seed"] = seed
    cfg.devices = parse_devices(devices)
    cfg.batch_size = 8
    cfg.model.extra_encoder = 'uni_v1_adapter'
    
    # è®¾ç½®éšæœºç§å­
    from lightning_fabric import seed_everything
    seed_everything(cfg["seed"])
    
    return cfg


def train_single_model(config_info):
    """
    è®­ç»ƒå•ä¸ªæ¨¡å‹çš„å‡½æ•°
    
    Args:
        config_info: åŒ…å«é…ç½®ä¿¡æ¯çš„å­—å…¸
    """
    try:
        print(f"\nğŸš€ Starting training: {config_info['name']}")
        print(f"   Config: {config_info['config_path']}")
        print(f"   Devices: {config_info['devices']}")
        print(f"   Project: {config_info['project']}")
        
        # åˆ›å»ºé…ç½®
        cfg = create_training_config(
            config_info['config_path'],
            config_info['project'],
            config_info['name'],
            config_info['devices'],
            config_info.get('seed', 42)
        )
        
        # æ‰“å°é…ç½®æ‘˜è¦
        print_config_summary(cfg)
        
        # å¼€å§‹è®­ç»ƒ
        trainer, pl_module = train_model(cfg)
        
        print(f"âœ… Training completed: {config_info['name']}")
        
    except Exception as e:
        print(f"âŒ Training failed for {config_info['name']}: {str(e)}")
        import traceback
        traceback.print_exc()


def run_parallel_training():
    """
    è¿è¡Œå¹¶è¡Œè®­ç»ƒ
    """
    # è®¾ç½®ç¯å¢ƒ
    setup_environment()
    
    # å®šä¹‰å¤šä¸ªè®­ç»ƒé…ç½®
    training_configs = [
        {
            'config_path': 'configs_run2.cd47nusc_HV_h5x128_debug',
            'project': 'FPNuNet-cd47nuscx128',
            'name': 'FPNuNet_cd47nuscx128_Mv231_GPU0',
            'devices': '0',
            'seed': 42
        },
        {
            'config_path': 'configs_run2.cd47nusc_HV_h5x128_debug',
            'project': 'FPNuNet-cd47nuscx128',
            'name': 'FPNuNet_cd47nuscx128_Mv231_GPU1',
            'devices': '1',
            'seed': 43
        },
        # å¯ä»¥æ·»åŠ æ›´å¤šé…ç½®...
    ]
    
    print(f"ğŸ¯ Starting parallel training with {len(training_configs)} configurations")
    
    # ä½¿ç”¨çº¿ç¨‹æ± è¿›è¡Œå¹¶è¡Œè®­ç»ƒ
    with ThreadPoolExecutor(max_workers=len(training_configs)) as executor:
        # æäº¤æ‰€æœ‰è®­ç»ƒä»»åŠ¡
        futures = [executor.submit(train_single_model, config) for config in training_configs]
        
        # ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆ
        for future in futures:
            future.result()
    
    print("ğŸ‰ All training tasks completed!")


def run_sequential_training():
    """
    è¿è¡Œé¡ºåºè®­ç»ƒï¼ˆä¸€ä¸ªæ¥ä¸€ä¸ªï¼‰
    """
    # è®¾ç½®ç¯å¢ƒ
    setup_environment()
    
    # å®šä¹‰å¤šä¸ªè®­ç»ƒé…ç½®
    training_configs = [
        {
            'config_path': 'configs_run2.cd47nusc_HV_h5x128_debug',
            'project': 'FPNuNet-cd47nuscx128',
            'name': 'FPNuNet_cd47nuscx128_Mv231_Sequential1',
            'devices': '0',
            'seed': 42
        },
        {
            'config_path': 'configs_run2.cd47nusc_HV_h5x128_debug',
            'project': 'FPNuNet-cd47nuscx128',
            'name': 'FPNuNet_cd47nuscx128_Mv231_Sequential2',
            'devices': '0',
            'seed': 43
        },
    ]
    
    print(f"ğŸ¯ Starting sequential training with {len(training_configs)} configurations")
    
    # é¡ºåºæ‰§è¡Œè®­ç»ƒ
    for i, config in enumerate(training_configs):
        print(f"\nğŸ“‹ Training {i+1}/{len(training_configs)}: {config['name']}")
        train_single_model(config)
        print(f"âœ… Completed {i+1}/{len(training_configs)}")
    
    print("ğŸ‰ All training tasks completed!")


if __name__ == '__main__':
    import argparse
    
    parser = argparse.ArgumentParser(description='Multi-model training script')
    parser.add_argument('--mode', type=str, default='sequential', 
                       choices=['sequential', 'parallel'],
                       help='Training mode: sequential or parallel')
    
    args = parser.parse_args()
    
    if args.mode == 'parallel':
        run_parallel_training()
    else:
        run_sequential_training()
