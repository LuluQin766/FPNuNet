import os
import json
import gc
import random
import numpy as np
import cv2
import time
from functools import partial

import torch
import torch.nn.functional as F
from torch import le, nn
from pytorch_lightning import LightningModule
from pytorch_lightning.callbacks import ModelCheckpoint
from torchmetrics import MetricCollection
from torch.utils.tensorboard import SummaryWriter

from losses_v5 import SAMLossV5 as SAM_Loss
from misc.viz_utils import visualize_maps_batch_train

DEBUG = False
# DEBUG = True    # True for printing debug messages

# èŽ·å–å½“å‰æ–‡ä»¶å
file_name = os.path.basename(__file__)
if "debug" in file_name:
    DEBUG = True

if DEBUG:
    print(f"\n ------ Debug mode is {DEBUG}  âœ… , setting on {file_name} ------ \n")

def get_prefix_from_val_id(dataloader_idx):
    if dataloader_idx is None or dataloader_idx == 0:
        return "valid"
    elif dataloader_idx == 1:
        return "test"
    else:
        raise NotImplementedError

def check_training_inputs(images, bin_map, inst_map, type_map, hv_map, patch_id):
    print(f"\nðŸŸ¡ Checking training batch {patch_id}")
    
    def check_tensor(name, tensor):
        print(f"\n -----  Checking {name}, dtype={tensor.dtype}, device={tensor.device}")
        if tensor is None:
            print(f"  âŒ {name} is None")
            return
        if torch.isnan(tensor).any():
            print(f"  âŒ {name} contains NaNs")
        if torch.isinf(tensor).any():
            print(f"  âŒ {name} contains Infs")
        unique_vals = torch.unique(tensor)
        print(f"  âœ… {name}: shape={tuple(tensor.shape)}, dtype={tensor.dtype}, unique={unique_vals[:8].tolist()}")

        if unique_vals.numel() > 8:
            print(f"    ... total unique: {unique_vals.numel()}")
        if name == 'bin_map' and not ((unique_vals == 0) | (unique_vals == 1)).all():
            print(f"  âš ï¸ Warning: {name} contains values outside [0, 1]")

    check_tensor("images", images)
    check_tensor("bin_map", bin_map)
    check_tensor("inst_map", inst_map)
    check_tensor("type_map", type_map)
    # check_tensor("hv_map", hv_map)

    # Extra: check range of hv_map (should be reasonably bounded)
    hv_max = hv_map.max().item()
    hv_min = hv_map.min().item()
    if abs(hv_max) > 100 or abs(hv_min) > 100:
        print(f"  âš ï¸ HV map values out of expected range: min={hv_min}, max={hv_max}")

def print_trainable_params(model):
    total = sum(p.numel() for p in model.parameters())
    trainable = sum(p.numel() for p in model.parameters() if p.requires_grad)
    print(f"\n âœ… Trainable parameters: {trainable:,} / {total:,} ({100 * trainable / total:.2f}%)\n")

class SamSegMultiHeadV6(LightningModule):
    def __init__(
            self,
            cfg,
            sam_model: nn.Module,
            metrics: MetricCollection,
            num_classes: int,
            lr: float = 1e-4,
            weight_decay: float = 1e-2,
            lr_steps: list = (10, 20),
            warmup_steps: int = 0,
            ignored_index=None,
            output_aux_tokens = False,
    ):
        """
        Args:
            cfg: configuration object containing paths and logging settings.
            sam_model (nn.Module): A multi-output SAM model that returns six outputs:
                (pred_masks_semantic, pred_masks_type, pred_masks_boundary,
                 ious_semantic, ious_type, ious_boundary).
            metrics (MetricCollection): A collection of metrics.
            num_classes (int): Number of segmentation classes.
            focal_cof, dice_cof, iou_cof, ce_cof: Loss coefficients.
            lr (float): Learning rate.
            weight_decay (float): Weight decay.
            lr_steps (list): Learning rate schedule steps.
            warmup_steps (int): Warmup steps.
            ignored_index: Class index to ignore (if any).
        """
        super().__init__()
        # save hyperparams except large objects
        self.ignored_index = ignored_index
        self.cfg = cfg
        self.batch_size = cfg.batch_size
        
        # åˆ†é˜¶æ®µè®­ç»ƒå‚æ•°
        self.unfreeze_epoch = cfg.opt.unfreeze_epoch if "unfreeze_epoch" in cfg.opt else None
        self.parameters_unfrozen = False  # æ ‡è®°å‚æ•°æ˜¯å¦å·²ç»é‡Šæ”¾
        
        self.save_hyperparameters(ignore=["sam_model", "metrics"])
        self.model = sam_model
        self.output_aux_tokens = output_aux_tokens

        # the model outputs:
        # {
        #     'bin': bin_map,
        #     'boundary': boundary,
        #     'hv': hv_out,
        #     'tp': type_out[-1],
        #     'bin_aux_outs': bin_aux_outs,
        #     'hv_aux_outs': hv_aux_outs,
        #     'type_aux_outs': type_out
        # }
        # å…¶ä¸­ aux_outs æ˜¯å„ä¸ªdecoderçš„è¾…åŠ©è¾“å‡ºï¼Œç”¨äºŽè¿›è¡ŒæŸå¤±è®¡ç®—

        print_trainable_params(self.model)
        
        # æ‰“å°åˆ†é˜¶æ®µè®­ç»ƒé…ç½®
        if self.unfreeze_epoch is not None:
            print(f"\nðŸŽ¯ åˆ†é˜¶æ®µè®­ç»ƒé…ç½®:")
            print(f"   - å‰ {self.unfreeze_epoch} ä¸ªepoch: å†»ç»“éƒ¨åˆ†å‚æ•°è®­ç»ƒ")
            print(f"   - ç¬¬ {self.unfreeze_epoch} ä¸ªepochå¼€å§‹: é‡Šæ”¾æ‰€æœ‰å‚æ•°è®­ç»ƒ")
        else:
            print(f"\nðŸ“ å¸¸è§„è®­ç»ƒæ¨¡å¼: ä½¿ç”¨é…ç½®æ–‡ä»¶ä¸­çš„å‚æ•°å†»ç»“è®¾ç½®")
        
        self.loss = SAM_Loss(
            bin_cof=cfg.loss.bin,
            tp_cof=cfg.loss.tp,
            hv_cof=cfg.loss.hv
        )

        # Suppose num_classes = number of cell types (excluding background)
        self.num_classes = num_classes + 1  # include background class

        print(" self.num_classes = ", self.num_classes)
        
        # metrics dict of metrics, each metric is a pytorch-lightning metric object
        # keys: 'bin', 'boundary', 'tp', 'hv'
        # each metric object is a MetricCollection object with a list of metrics including 'iou_micro', 'dice_macro', 'f1_macro'

        self.train_metrics = nn.ModuleDict({
            head: metrics[head].clone() for head in metrics
        })
        self.valid_metrics = nn.ModuleList([
            nn.ModuleDict({
                head: metrics[head].clone() for head in metrics
            }), 
            nn.ModuleDict({
                head: metrics[head].clone() for head in metrics
            })
        ])
        self.test_metrics = nn.ModuleDict({
            head: metrics[head].clone() for head in metrics
        })

        print("\n --------- SAMSegMultiHeadV4 initialized metrices: ")
        print("\n Train metrics: ", self.train_metrics)
        print("\n Valid metrics: ", self.valid_metrics)
        print("\n Test metrics: ", self.test_metrics)
        print("\n")

        # optimization params
        self.lr = lr
        self.lr_steps = lr_steps
        self.hparams.lr_steps = lr_steps if lr_steps is not None else [10000, 20000]  # default steps if None
        
        self.weight_decay = weight_decay
        self.warmup_steps = warmup_steps

        # logging setup
        os.makedirs(cfg.log_dir, exist_ok=True)
        self.log_file_path = os.path.join(cfg.log_dir, 'training_log_new.json')
        self.plot_save_dir = os.path.join(cfg.log_dir, 'training_plots')
        os.makedirs(self.plot_save_dir, exist_ok=True)
        
        # TensorBoard setup
        self.tensorboard_dir = os.path.join(cfg.log_dir, 'tensorboard')
        os.makedirs(self.tensorboard_dir, exist_ok=True)
        self.writer = SummaryWriter(log_dir=self.tensorboard_dir)
        
        # è®°å½•é¢‘çŽ‡æŽ§åˆ¶
        self.log_frequency = 20  # æ¯20æ­¥è®°å½•ä¸€æ¬¡losså’Œmetrics
        self.image_log_frequency = 200  # æ¯200æ­¥è®°å½•ä¸€æ¬¡å›¾åƒ
        self.save_log_frequency = 100  # æ¯100æ­¥ä¿å­˜ä¸€æ¬¡æ—¥å¿—åˆ°ç£ç›˜
        self.log_buffer_size = 0  # æ—¥å¿—ç¼“å†²åŒºå¤§å°è®¡æ•°å™¨
        
        # æ‰“å°æ—¥å¿—è®°å½•é¢‘çŽ‡é…ç½®
        print(f"\nðŸ“Š æ—¥å¿—è®°å½•é¢‘çŽ‡é…ç½®:")
        print(f"   - Lossè®°å½•é¢‘çŽ‡: æ¯{self.log_frequency}æ­¥")
        print(f"   - å›¾åƒè®°å½•é¢‘çŽ‡: æ¯{self.image_log_frequency}æ­¥")
        print(f"   - ç£ç›˜ä¿å­˜é¢‘çŽ‡: æ¯{self.save_log_frequency}æ­¥")
        # self._init_log()
        # initialize structured log data for multi-head losses and metrics
        
        def get_loss_units(head):
            if head == 'bin':
                return {'loss':[], 'bce':[], 'dice':[], 'focal':[]}
            elif head == 'hv':
                return {'loss':[], 'mse':[], 'msge':[]}
            else:
                return {'loss':[], 'ce':[], 'dice':[], 'focal':[], 'iou':[]}    # tp

        def get_metric_units(head, num_classes=None):
            # print(f"\n -------- get_metric_units for {head} with num_classes={num_classes}")
            if head == 'cls':
                metric_dict = {
                    'iou_micro': [],
                    'dice_macro': [],
                    'f1_macro': [],
                }
                # è‡ªåŠ¨æ·»åŠ  class-wise
                if num_classes is not None:
                    for i in range(1, num_classes):  # skip background (0)
                        metric_dict[f'iou_class_{i}'] = []
                        metric_dict[f'dice_class_{i}'] = []
                return metric_dict
            else:   # hv
                return {'mse':[],'mae':[], "msge": []}
        
        def get_loss_items_with_aux():
            return {
            "losses": {
                "bin": {
                    "bin": get_loss_units('bin'), 
                    "boundary": get_loss_units('bin'), 
                    "bin_aux_0": get_loss_units('bin'), 
                    "bin_aux_1": get_loss_units('bin'), 
                    "bin_loss": []
                },
                "hv": {
                    "hv": get_loss_units('hv'), 
                    "hv_aux_0": get_loss_units('hv'), 
                    "hv_aux_1": get_loss_units('hv'), 
                    "hv_loss": []
                },
                "tp": {
                    "tp": get_loss_units('tp'), 
                    "tp_aux_0": get_loss_units('tp', num_classes=self.num_classes), 
                    "tp_aux_1": get_loss_units('tp', num_classes=self.num_classes), 
                    "tp_aux_2": get_loss_units('tp', num_classes=self.num_classes), 
                    "tp_loss": []
                },
                "total_loss": []
            },
            "metrics": {
                "bin": {
                    "bin": get_metric_units('cls'),
                    "bin_aux_0": get_metric_units('cls'),
                    "bin_aux_1": get_metric_units('cls'),
                },
                "boundary": get_metric_units('cls'),
                "tp": {
                    "tp": get_metric_units('cls', num_classes=self.num_classes),
                    "tp_aux_0": get_metric_units('cls', num_classes=self.num_classes),
                    "tp_aux_1": get_metric_units('cls', num_classes=self.num_classes),
                    "tp_aux_2": get_metric_units('cls', num_classes=self.num_classes),
                },
                "hv": {
                    "hv": get_metric_units('hv'),
                    "hv_aux_0": get_metric_units('hv'),
                    "hv_aux_1": get_metric_units('hv'),
                },
            },
            "epochs": []
        }
        
        def get_loss_items():
            return {
            "losses": {
                "bin": {
                    "bin": get_loss_units('bin'), 
                    "boundary": get_loss_units('bin'), 
                    "bin_loss": []
                },
                "hv": {
                    "hv": get_loss_units('hv'), 
                    "hv_loss": []
                },
                "tp": {
                    "tp": get_loss_units('tp'), 
                    "tp_loss": []
                },
                "total_loss": []
            },
            "metrics": {
                "bin": {
                    "bin": get_metric_units('cls'),
                },
                "boundary": get_metric_units('cls'),
                "tp": {
                    "tp": get_metric_units('cls', num_classes=self.num_classes),
                },
                "hv": {
                    "hv": get_metric_units('hv'),
                },
            },
            "epochs": []
        }

        if self.output_aux_tokens:
            self.log_data = {
                "train": get_loss_items_with_aux(),
                "valid": get_loss_items_with_aux(),
                "test": get_loss_items_with_aux(),
                "train_epoch": get_loss_items_with_aux(),
                "valid_epoch": get_loss_items_with_aux(),
                "test_epoch": get_loss_items_with_aux()
            }
        else:
            self.log_data = {
                "train": get_loss_items(),
                "valid": get_loss_items(),
                "test": get_loss_items(),
                "train_epoch": get_loss_items(),
                "valid_epoch": get_loss_items(),
                "test_epoch": get_loss_items()
            }
        # # åˆå§‹åŒ– log_data ç»“æž„ï¼ˆä¾‹å¦‚ train_epochï¼‰
        # for split in ["train", "valid", "test"]:
        #     for epoch in ["", "_epoch"]:
        #         key = split + epoch
        #         if key not in self.log_data:
        #             self.log_data[key] = {"metrics": {}}
        #         for head in ["bin", "boundary", "tp", "hv"]:
        #             if head not in self.log_data[key]["metrics"]:
        #                 self.log_data[key]["metrics"][head] = {head: {}}

        self._save_log()

    def _save_log(self):
        """ä¼˜åŒ–çš„æ—¥å¿—ä¿å­˜æ–¹æ³•ï¼Œä½¿ç”¨æ›´é«˜æ•ˆçš„å†™å…¥ç­–ç•¥"""
        try:
            # ä½¿ç”¨ä¸´æ—¶æ–‡ä»¶é¿å…å†™å…¥è¿‡ç¨‹ä¸­çš„æ•°æ®æŸå
            temp_file_path = self.log_file_path + '.tmp'
            with open(temp_file_path, 'w') as f:
                json.dump(self.log_data, f, indent=4)
            
            # åŽŸå­æ€§é‡å‘½åï¼Œç¡®ä¿æ•°æ®å®Œæ•´æ€§
            import shutil
            shutil.move(temp_file_path, self.log_file_path)
            
        except Exception as e:
            print(f"Error saving log file to {self.log_file_path}: {e}")
            pass
    
    def _force_save_log(self):
        """å¼ºåˆ¶ä¿å­˜æ—¥å¿—ï¼Œç”¨äºŽè®­ç»ƒç»“æŸæ—¶ç¡®ä¿æ•°æ®ä¸ä¸¢å¤±"""
        self._save_log()
        print(f"ðŸ’¾ å¼ºåˆ¶ä¿å­˜æ—¥å¿—åˆ°: {self.log_file_path}")
    
    def _log_performance_stats(self):
        """è®°å½•æ€§èƒ½ç»Ÿè®¡ä¿¡æ¯"""
        if hasattr(self, 'log_buffer_size') and self.log_buffer_size > 0:
            avg_save_frequency = self.log_buffer_size / max(1, self.current_epoch + 1)
            print(f"ðŸ“Š æ—¥å¿—æ€§èƒ½ç»Ÿè®¡:")
            print(f"   - æ€»æ­¥æ•°: {self.log_buffer_size}")
            print(f"   - å¹³å‡æ¯epochä¿å­˜æ¬¡æ•°: {avg_save_frequency:.1f}")
            print(f"   - ç£ç›˜å†™å…¥ä¼˜åŒ–: æ¯{self.save_log_frequency}æ­¥ä¿å­˜ä¸€æ¬¡")
            print(f"   - å›¾åƒè®°å½•é¢‘çŽ‡: æ¯{self.image_log_frequency}æ­¥è®°å½•ä¸€æ¬¡")

    def forward(self, images):
        # returns dict: {'bin':BÃ—1Ã—HÃ—W, 'tp':BÃ—CÃ—HÃ—W, 'hv':BÃ—2Ã—HÃ—W, 'aux_preds':[...]} 
        outputs = self.model(images)
        # if DEBUG: 
        #     print("\n -------- Forward pass complete ")
        #     self.print_dict(outputs)
        return outputs

    @torch.no_grad()
    def process_masks(self, gt_masks):
        # gt_masks: [B,H,W]
        ignored = (gt_masks == 0).unsqueeze(1).long()
        return gt_masks.long(), ignored
    
    def predict_mask_process(self, preds: dict):
        """
        Convert model outputs into predicted masks for each head.
        """
        # Binary head
        def bin_sigmoid_threshold(logit, threshold=0.5):
            logit = torch.sigmoid(logit)  # [B, 1, H, W]
            return (logit > threshold).long().squeeze(1)  # [B, H, W]
        
        def class_one_hot_from_logits(logits: torch.Tensor):
            # logits: [B, C, H, W] -> one-hot: [B, C, H, W]
            class_idx = torch.argmax(logits, dim=1)               # [B, H, W]
            one_hot = F.one_hot(class_idx, self.num_classes)           # [B, H, W, C]
            one_hot = one_hot.permute(0, 3, 1, 2).contiguous()     # [B, C, H, W]
            return one_hot
        
        def class_idx_from_logits(logits: torch.Tensor):
            # logits: [B, C, H, W] -> class indices: [B, H, W]
            return torch.argmax(logits, dim=1)

        output_dict = {
            'bin': bin_sigmoid_threshold(preds['bin']),             # shape: [B, 1, H, W] -> squeeze(1) => [B, H, W]
            'boundary': bin_sigmoid_threshold(preds['boundary']),   # shape: [B, 1, H, W] -> squeeze(1) => [B, H, W]
            'hv': torch.sigmoid(preds['hv']).float(),      # [B, 2, H, W], HV æ˜¯ regression mapï¼Œä¿æŒä¸å˜
            'tp': class_idx_from_logits(preds['tp']),        # [B, C, H, W] -> argmax(dim=1) => [B, H, W]
        }

        if self.output_aux_tokens:
            output_dict.update({
                'bin_aux_0': bin_sigmoid_threshold(preds['bin_aux_outs'][0]),         # [B, 1, H//4, W//4] -> squeeze(1) => [B, H//4, W//4]
                'bin_aux_1': bin_sigmoid_threshold(preds['bin_aux_outs'][1]),         # [B, 1, H//2, W//2] -> squeeze(1) => [B, H//2, W//2]
                'type_aux_0': class_one_hot_from_logits(preds['type_aux_outs'][0]),   # [B, C+1, H//4, W//4] -> argmax(dim=1) => [B, H//4, W//4]
                'type_aux_1': class_one_hot_from_logits(preds['type_aux_outs'][1]),   # [B, C+1, H//2, W//2] -> argmax(dim=1) => [B, H//2, W//2]
                'type_aux_2': class_one_hot_from_logits(preds['type_aux_outs'][2]),   # [B, C+1, H, W] -> argmax(dim=1) => [B, H, W]
                'hv_aux_0': torch.sigmoid(preds['hv_aux_outs'][0]).float(),     # [B, 2, H//4, W//4]ï¼ŒHV æ˜¯ regressionï¼Œä¿æŒä¸å˜
                'hv_aux_1': torch.sigmoid(preds['hv_aux_outs'][1]).float(),     # [B, 2, H//2, W//2]ï¼ŒHV æ˜¯ regressionï¼Œä¿æŒä¸å˜
            })

        return output_dict
    
    def gts_mask_process(self, input_dict):
        output_dict = {
            'bin': input_dict['bin'].squeeze(1),    # [B, 1, H, W] -> squeeze(1) => [B, H, W]
            'boundary': input_dict['boundary'].squeeze(1),   # [B, 1, H, W] -> squeeze(1) => [B, H, W]
            'hv': input_dict['hv'].float(),      # [B, 2, H, W], HV æ˜¯ regression mapï¼Œä¿æŒä¸å˜
            'tp': input_dict["tp"].long(),    # [B, H, W] -> ä¿æŒç±»åˆ«ç´¢å¼•æ ¼å¼
        }

        if self.output_aux_tokens:
            output_dict.update({
                'bin_aux_0': input_dict['bin_aux_outs'][0],   # [B, 1, H//4, W//4] -> squeeze(1) => [B, H//4, W//4]
                'bin_aux_1': input_dict['bin_aux_outs'][1],   # [B, 1, H//2, W//2] -> squeeze(1) => [B, H//2, W//2]
                'type_aux_0': F.one_hot(input_dict["type_aux_outs"][0], self.num_classes).permute(0,3,1,2).contiguous(),   # [B, H//4, W//4] -> one_hot -> [B, C+1, H//4, W//4]
                'type_aux_1': F.one_hot(input_dict["type_aux_outs"][1], self.num_classes).permute(0,3,1,2).contiguous(),   # [B, H//2, W//2] -> one_hot -> [B, C+1, H//2, W//2]
                'type_aux_2': F.one_hot(input_dict["tp"], self.num_classes).permute(0,3,1,2).contiguous(),    # [B, H, W] -> one_hot -> [B, C, H, W]
                'hv_aux_0': input_dict['hv_aux_outs'][0].float(),     # [B, 2, H//4, W//4]ï¼ŒHV æ˜¯ regressionï¼Œä¿æŒä¸å˜
                'hv_aux_1': input_dict['hv_aux_outs'][1].float(),     # [B, 2, H//2, W//2]ï¼ŒHV æ˜¯ regressionï¼Œä¿æŒä¸å˜
            })
        return output_dict
    
    def update_metrics(self, metric_dict, preds_onehots, gts_onehots):
        """
        metric_dict: nn.ModuleDict, æ¯ä¸ªåˆ†æ”¯ä¸€ä¸ª MetricCollection
        preds_onehots: dict, åŒ…å«æ¨¡åž‹é¢„æµ‹çš„ one-hot æ ‡ç­¾
        gts_onehots: dict, åŒ…å« GT æ ‡ç­¾çš„ one-hot æ ‡ç­¾
        """
        for key in metric_dict.keys():
            if key not in preds_onehots or key not in gts_onehots:
                continue
            pred = preds_onehots[key]
            gt = gts_onehots[key]

            # å¤„ç†è¾…åŠ©è¾“å‡ºï¼ˆæ³¨æ„ shape æ ¼å¼ï¼‰
            if isinstance(pred, list) and isinstance(gt, list):
                for i, (pi, gi) in enumerate(zip(pred, gt)):
                    sub_key = f"{key}_{i}"
                    if sub_key in metric_dict:
                        metric_dict[sub_key].update(pi, gi)
            else:
                metric_dict[key].update(pred, gt)


    def print_dict(self, data_dict):
        print("\n -------- data_dict keys: ", data_dict.keys())
        for k, v in data_dict.items():
            if isinstance(v, (list, tuple)):
                print(f" ---- {k}: len={len(v)}")
                for i, vi in enumerate(v):
                    print(f"  {k}[{i}]: shape={vi.shape}, dtype={vi.dtype}, values range: [{vi.min().item()}, {vi.max().item()}]")
            else:
                print(f" ---- {k}: shape={v.shape}, dtype={v.dtype}, values range: [{v.min().item()}, {v.max().item()}]")
        print("\n")
    
    def log_losses(self, loss_dict, prefix="train", on_step=False, on_epoch=True):
        """
        Recursively log all scalar values in a nested dictionary.
        """
        for key, value in loss_dict.items():
            if isinstance(value, dict):
                self.log_losses(value, prefix=f"{prefix}/losses/{key}", on_step=on_step, on_epoch=on_epoch)
            elif isinstance(value, (float, int, torch.Tensor)):
                if isinstance(value, torch.Tensor):
                    value = value.detach()
                self.log(f"{prefix}/{key}", value, on_step=on_step, on_epoch=on_epoch, prog_bar=False, batch_size=self.batch_size)
    
    def log_to_tensorboard(self, losses, metrics=None, prefix="train", step=None):
        """
        å°†losseså’Œmetricsè®°å½•åˆ°TensorBoard
        """
        if step is None:
            step = self.global_step
        
        # è®°å½•losses
        self._log_losses_to_tb(losses, prefix, step)
        
        # è®°å½•metrics
        if metrics is not None:
            self._log_metrics_to_tb(metrics, prefix, step)
    
    def _log_losses_to_tb(self, losses, prefix, step):
        """
        é€’å½’è®°å½•lossesåˆ°TensorBoard
        """
        for key, value in losses.items():
            if isinstance(value, dict):
                self._log_losses_to_tb(value, f"{prefix}/{key}", step)
            elif isinstance(value, (float, int, torch.Tensor)):
                if isinstance(value, torch.Tensor):
                    value = value.detach().item()
                self.writer.add_scalar(f"{prefix}/{key}", value, step)
    
    def _log_metrics_to_tb(self, metrics, prefix, step):
        """
        è®°å½•metricsåˆ°TensorBoard
        """
        for head_key, collection in metrics.items():
            if not hasattr(collection, "compute"):
                continue
            
            computed_metrics = collection.compute()
            for metric_name, metric_val in computed_metrics.items():
                if isinstance(metric_val, (list, tuple)):
                    values = metric_val
                elif isinstance(metric_val, torch.Tensor) and metric_val.ndim == 1:
                    values = metric_val.tolist()
                else:
                    values = [metric_val.item()]
                
                if metric_name in ["iou_classwise", "dice_classwise"]:
                    for cls_idx, val in enumerate(values):
                        if cls_idx == 0:  # skip background
                            continue
                        key = f"{metric_name.split('_')[0]}_class_{cls_idx}"
                        self.writer.add_scalar(f"{prefix}/metrics/{head_key}/{key}", val, step)
                else:
                    val = values[0]
                    self.writer.add_scalar(f"{prefix}/metrics/{head_key}/{metric_name}", val, step)
    
    def log_images_to_tensorboard(self, images, preds, gts, prefix="train", step=None):
        """
        å°†å›¾åƒè®°å½•åˆ°TensorBoardï¼ŒæŒ‰ç…§æŒ‡å®šçš„2è¡Œ6åˆ—å¸ƒå±€
        ç¬¬ä¸€è¡Œï¼šè¾“å…¥å›¾ï¼ŒGT inst_mapï¼ŒGT np_mapï¼ŒGT type_mapï¼ŒGT h mapï¼ŒGT v map
        ç¬¬äºŒè¡Œï¼šoverlayå›¾ï¼Œpred inst_mapï¼Œpred np_mapï¼Œpred type_mapï¼Œpred h mapï¼Œpred v map
        """
        if step is None:
            step = self.current_epoch
        
        # åªè®°å½•ç¬¬ä¸€ä¸ªbatchçš„å›¾åƒ
        batch_size = min(1, images.shape[0])  # åªè®°å½•1å¼ å›¾åƒ
        
        for i in range(batch_size):
            # åŽŸå§‹å›¾åƒ
            img = images[i].detach().cpu().numpy()  # [H, W, 3]
            img = np.transpose(img, (2, 0, 1))  # [3, H, W]
            
            # å½’ä¸€åŒ–åˆ°[0,1]
            img = (img - img.min()) / (img.max() - img.min() + 1e-8)
            
            # èŽ·å–é¢„æµ‹å’ŒçœŸå®žæ ‡ç­¾
            pred_bin = preds['bin'][i].detach().cpu().numpy()  # [H, W]
            pred_tp = preds['tp'][i].detach().cpu().numpy()  # [H, W] - å·²ç»æ˜¯ç±»åˆ«ç´¢å¼•æ ¼å¼
            pred_hv = preds['hv'][i].detach().cpu().numpy()  # [2, H, W]
            
            gt_bin = gts['bin'][i].detach().cpu().numpy()  # [H, W]
            gt_tp = gts['tp'][i].detach().cpu().numpy()  # [H, W] - å·²ç»æ˜¯ç±»åˆ«ç´¢å¼•æ ¼å¼
            gt_hv = gts['hv'][i].detach().cpu().numpy()  # [2, H, W]
            
            # ç”Ÿæˆé¢„æµ‹çš„inst_mapï¼ˆä½¿ç”¨åŽå¤„ç†ï¼‰
            pred_inst_map = self._generate_pred_inst_map(pred_bin, pred_hv)
            
            # ç”Ÿæˆoverlayå›¾åƒ
            overlay_img = self._generate_overlay_image(img, pred_inst_map, pred_tp)
            
            # åˆ›å»ºé¢œè‰²æ˜ å°„çš„type_map
            gt_type_colored = self._create_colored_type_map(gt_tp)
            pred_type_colored = self._create_colored_type_map(pred_tp)
            
            # åˆ›å»º2è¡Œ6åˆ—çš„å›¾åƒç½‘æ ¼
            # ç¬¬ä¸€è¡Œï¼šè¾“å…¥å›¾ï¼ŒGT inst_mapï¼ŒGT np_mapï¼ŒGT type_mapï¼ŒGT h mapï¼ŒGT v map
            row1_images = [
                img,  # è¾“å…¥å›¾ [3, H, W]
                self._create_inst_rgb_mask(gt_tp),  # GT inst_map (ä½¿ç”¨type_mapä½œä¸ºproxy)
                gt_bin,  # GT np_map [H, W] -> [1, H, W]
                gt_type_colored,  # GT type_map [H, W, 3] -> [3, H, W]
                gt_hv[0:1],  # GT h map [1, H, W]
                gt_hv[1:2],  # GT v map [1, H, W]
            ]
            
            # ç¬¬äºŒè¡Œï¼šoverlayå›¾ï¼Œpred inst_mapï¼Œpred np_mapï¼Œpred type_mapï¼Œpred h mapï¼Œpred v map
            row2_images = [
                overlay_img,  # overlayå›¾ [3, H, W]
                self._create_inst_rgb_mask(pred_inst_map),  # pred inst_map [3, H, W]
                pred_bin,  # pred np_map [H, W] -> [1, H, W]
                pred_type_colored,  # pred type_map [H, W, 3] -> [3, H, W]
                pred_hv[0:1],  # pred h map [1, H, W]
                pred_hv[1:2],  # pred v map [1, H, W]
            ]
            
            # ç¡®ä¿æ‰€æœ‰å›¾åƒéƒ½æ˜¯3é€šé“æ ¼å¼
            processed_images = []
            for img_list in [row1_images, row2_images]:
                for img_data in img_list:
                    if img_data.ndim == 2:  # [H, W] -> [1, H, W] -> [3, H, W]
                        img_data = np.stack([img_data, img_data, img_data], axis=0)
                    elif img_data.ndim == 3 and img_data.shape[0] == 1:  # [1, H, W] -> [3, H, W]
                        img_data = np.repeat(img_data, 3, axis=0)
                    elif img_data.ndim == 3 and img_data.shape[2] == 3:  # [H, W, 3] -> [3, H, W]
                        img_data = np.transpose(img_data, (2, 0, 1))
                    processed_images.append(img_data)
            
            # åˆ›å»ºå›¾åƒç½‘æ ¼ (2è¡Œ6åˆ—)
            image_grid = torch.from_numpy(np.stack(processed_images, axis=0))  # [12, 3, H, W]
            
            # è®°å½•åˆ°TensorBoard
            self.writer.add_images(f"{prefix}/visualization", image_grid, step)
            
            # åŒæ—¶ä¿å­˜åˆ°æ–‡ä»¶å¤¹
            self._save_visualization_images(img, processed_images, prefix, step)
    
    def _generate_pred_inst_map(self, pred_bin, pred_hv):
        """
        ä½¿ç”¨åŽå¤„ç†ç”Ÿæˆé¢„æµ‹çš„inst_map
        """
        try:
            # å¯¼å…¥åŽå¤„ç†æ¨¡å—
            import sys
            sys.path.append('/root/SAM2PATH-main')
            from postprocess.post_process_v2 import __proc_np_hv
            
            # è½¬æ¢æ•°æ®æ ¼å¼
            np_map = pred_bin.astype(np.float32)
            hv_map = pred_hv.transpose(1, 2, 0).astype(np.float32)  # [H, W, 2]
            
            # è°ƒç”¨åŽå¤„ç†å‡½æ•°
            pred_inst_map = __proc_np_hv(np_map, hv_map, threshold=0.5)
            
            return pred_inst_map
            
        except Exception as e:
            if DEBUG:
                print(f"Error in post-processing: {e}")
            # å¦‚æžœåŽå¤„ç†å¤±è´¥ï¼Œè¿”å›žç®€å•çš„äºŒå€¼å›¾
            return (pred_bin > 0.5).astype(np.int32)
    
    def _generate_overlay_image(self, img, inst_map, type_map):
        """
        ç”Ÿæˆoverlayå›¾åƒï¼Œå°†æ¯ä¸ªæ ¸å®žä¾‹çš„è¾¹ç•Œçº¿ç»˜åˆ¶åœ¨è¾“å…¥å›¾ä¸Š
        """
        try:
            # è½¬æ¢å›¾åƒæ ¼å¼ [3, H, W] -> [H, W, 3]
            overlay_img = img.transpose(1, 2, 0).copy()
            
            # èŽ·å–æ‰€æœ‰å”¯ä¸€çš„instance ID
            unique_instances = np.unique(inst_map)
            unique_instances = unique_instances[unique_instances > 0]  # æŽ’é™¤èƒŒæ™¯
            
            # ä¸ºæ¯ä¸ªinstanceç»˜åˆ¶overlay
            for inst_id in unique_instances:
                # èŽ·å–å½“å‰instanceçš„mask
                inst_mask = (inst_map == inst_id)
                
                # èŽ·å–è¯¥instanceçš„ç±»åž‹
                inst_pixels = inst_mask & (type_map > 0)
                if not np.any(inst_pixels):
                    continue
                
                # èŽ·å–è¯¥instanceçš„ä¸»è¦ç±»åž‹
                inst_type_values = type_map[inst_pixels]
                inst_type_id = np.bincount(inst_type_values).argmax()
                
                # èŽ·å–è¯¥ç±»åž‹çš„é¢œè‰²
                type_id_str = str(inst_type_id)
                if type_id_str in self.cfg.dataset.color_dict:
                    type_name, type_color = self.cfg.dataset.color_dict[type_id_str]
                    color_normalized = np.array(type_color) / 255.0
                else:
                    color_normalized = np.array([1.0, 1.0, 1.0])  # é»˜è®¤ç™½è‰²
                
                # æ‰¾åˆ°è¯¥instanceçš„è½®å»“
                from skimage import measure
                contours = measure.find_contours(inst_mask.astype(float), 0.5)
                
                # åœ¨overlayå›¾åƒä¸Šç»˜åˆ¶è½®å»“
                for contour in contours:
                    contour_coords = np.round(contour).astype(int)
                    valid_coords = (contour_coords[:, 0] >= 0) & (contour_coords[:, 0] < inst_mask.shape[0]) & \
                                  (contour_coords[:, 1] >= 0) & (contour_coords[:, 1] < inst_mask.shape[1])
                    contour_coords = contour_coords[valid_coords]
                    
                    if len(contour_coords) > 0:
                        # ç»˜åˆ¶è½®å»“çº¿
                        for y, x in contour_coords:
                            if 0 <= y < overlay_img.shape[0] and 0 <= x < overlay_img.shape[1]:
                                overlay_img[y, x] = color_normalized
            
            # è½¬æ¢å›ž [3, H, W] æ ¼å¼
            return overlay_img.transpose(2, 0, 1)
            
        except Exception as e:
            if DEBUG:
                print(f"Error generating overlay: {e}")
            return img
    
    def _create_colored_type_map(self, type_map):
        """
        æ ¹æ®JSONæ–‡ä»¶åˆ›å»ºé¢œè‰²æ˜ å°„çš„type_map
        """
        try:
            colored_map = np.zeros((*type_map.shape, 3), dtype=np.float32)
            
            for type_id_str, (type_name, type_color) in self.cfg.dataset.color_dict.items():
                type_id = int(type_id_str)
                mask = (type_map == type_id)
                color_normalized = np.array(type_color) / 255.0
                colored_map[mask] = color_normalized
            
            return colored_map
            
        except Exception as e:
            if DEBUG:
                print(f"Error creating colored type map: {e}")
            # è¿”å›žç°åº¦å›¾
            return np.stack([type_map / self.num_classes] * 3, axis=2)
    
    def _create_inst_rgb_mask(self, inst_map):
        """
        åˆ›å»ºåŸºäºŽinst_mapçš„RGB maskï¼Œæ¯ä¸ªinstanceéšæœºåˆ†é…ä¸€ä¸ªé¢œè‰²
        """
        try:
            # èŽ·å–æ‰€æœ‰å”¯ä¸€çš„instance ID
            unique_instances = np.unique(inst_map)
            unique_instances = unique_instances[unique_instances > 0]  # æŽ’é™¤èƒŒæ™¯
            
            # åˆ›å»ºRGB mask
            rgb_mask = np.zeros((*inst_map.shape, 3), dtype=np.float32)
            
            # ä¸ºæ¯ä¸ªinstanceåˆ†é…éšæœºé¢œè‰²
            np.random.seed(42)  # è®¾ç½®éšæœºç§å­ä»¥ç¡®ä¿ç»“æžœå¯é‡çŽ°
            for inst_id in unique_instances:
                # ç”ŸæˆéšæœºRGBé¢œè‰²
                color = np.random.rand(3)
                
                # åº”ç”¨é¢œè‰²åˆ°è¯¥instanceçš„æ‰€æœ‰åƒç´ 
                inst_mask = (inst_map == inst_id)
                rgb_mask[inst_mask] = color
            
            return rgb_mask.transpose(2, 0, 1)  # [3, H, W]
            
        except Exception as e:
            if DEBUG:
                print(f"Error creating inst RGB mask: {e}")
            # è¿”å›žç°åº¦å›¾
            return np.stack([inst_map / (inst_map.max() + 1e-8)] * 3, axis=0)
    
    def _save_visualization_images(self, img, processed_images, prefix, step):
        """
        ä¿å­˜å¯è§†åŒ–å›¾åƒåˆ°æ–‡ä»¶å¤¹
        """
        try:
            # åˆ›å»ºä¿å­˜ç›®å½•
            visuals_dir = os.path.join(self.cfg.log_dir, f"{prefix}_visuals")
            os.makedirs(visuals_dir, exist_ok=True)
            
            # ä¿å­˜å›¾åƒ
            import matplotlib.pyplot as plt
            fig, axes = plt.subplots(2, 6, figsize=(24, 8))
            fig.suptitle(f'{prefix.capitalize()} Visualization - Epoch {step}', fontsize=16)
            
            # å›¾åƒæ ‡é¢˜
            titles = [
                'Input Image', 'GT Inst Map', 'GT NP Map', 'GT Type Map', 'GT H Map', 'GT V Map',
                'Overlay', 'Pred Inst Map', 'Pred NP Map', 'Pred Type Map', 'Pred H Map', 'Pred V Map'
            ]
            
            for i, (img_data, title) in enumerate(zip(processed_images, titles)):
                row = i // 6
                col = i % 6
                
                if img_data.ndim == 3 and img_data.shape[0] == 3:  # [3, H, W]
                    img_display = img_data.transpose(1, 2, 0)
                else:
                    img_display = img_data[0] if img_data.ndim == 3 else img_data
                
                axes[row, col].imshow(img_display)
                axes[row, col].set_title(title)
                axes[row, col].axis('off')
            
            plt.tight_layout()
            
            # ä¿å­˜å›¾åƒ
            save_path = os.path.join(visuals_dir, f'epoch_{step:03d}.png')
            plt.savefig(save_path, dpi=150, bbox_inches='tight')
            plt.close()
            
            if DEBUG:
                print(f"Visualization saved to: {save_path}")
                
        except Exception as e:
            if DEBUG:
                print(f"Error saving visualization: {e}")
        

    def safe_log_losses(self, losses: dict, prefix: str, on_step=False, on_epoch=True):
        text = "_epoch" if on_epoch else ""

        # === Losses ===
        # print("\nðŸ”» --------- Losses:")
        # for head, items in losses.items():
        #     if isinstance(items, dict):
        #         print(f"  â–¶ {head}:")
        #         for sub_key, vals in items.items():
        #             if isinstance(vals, dict):  # e.g., dice/bce/focal breakdown
        #                 line = f"    {sub_key}: "
        #                 for metric_name, val_list in vals.items():
        #                     preview = val_list[-max_entries:] if isinstance(val_list, list) else val_list
        #                     line += f"{metric_name}={preview}  "
        #                 print(line)
        #             else:
        #                 preview = vals[-max_entries:] if isinstance(vals, list) else vals
        #                 print(f"    {sub_key}: {preview}")
        #     else:
        #         preview = items[-max_entries:] if isinstance(items, list) else items
        #         print(f"  â–¶ {head}: {preview}")
        # print("\n")

        for key, value in losses.items():
            if isinstance(value, dict):
                # e.g. losses["tp"] = {"loss": ..., "ce": ..., ...}
                for sub_key, sub_val in value.items():
                    if isinstance(sub_val, dict):
                        # Deep nested dict, e.g. losses["tp"]["tp"]["ce"]
                        for subsub_key, subsub_val in sub_val.items():
                            val = subsub_val.item() if torch.is_tensor(subsub_val) else subsub_val
                            try:
                                self.log_data[prefix]["losses"][key][sub_key][subsub_key].append(val)
                            except KeyError:
                                if key == "boundary":
                                    self.log_data[prefix]["losses"]["bin"][key][subsub_key].append(val)
                                else:
                                    raise KeyError(f"Missing log entry: [{prefix}]['losses'][{key}][{sub_key}][{subsub_key}]")
                    else:
                        # One level dict, e.g. losses["tp"]["ce"]
                        val = sub_val.item() if torch.is_tensor(sub_val) else sub_val
                        try:
                            self.log_data[prefix]["losses"][key][key][sub_key].append(val)
                        except KeyError:
                            if key == "boundary":
                                self.log_data[prefix]["losses"]["bin"][key][sub_key].append(val)
                            else:
                                raise KeyError(f"Missing log entry: [{prefix}]['losses'][{key}][{key}][{sub_key}]")
            else:
                # Summary losses: e.g. bin_loss, hv_loss, tp_loss, total_loss
                val = value.item() if torch.is_tensor(value) else value
                if key in ["bin_loss", "hv_loss", "tp_loss"]:
                    for branch in ["bin", "hv", "tp"]:
                        if key in self.log_data[prefix]["losses"].get(branch, {}):
                            self.log_data[prefix]["losses"][branch][key].append(val)
                            break
                elif key == "total_loss":
                    self.log_data[prefix]["losses"]["total_loss"].append(val)
                else:
                    raise KeyError(f"Unexpected loss key: {key}")
    

    def safe_log_metrics(self, metric_collections, prefix: str, on_step=False, on_epoch=True):
        text = "_epoch" if on_epoch else ""

        # # === Print Metrics Results ===
        # print(f"\n -------- ðŸ”· {prefix}{text} metric_collections, keys: ", metric_collections.keys())
        # for head, items in metric_collections.items():
        #     if isinstance(items, dict):
        #         print(f"  â–¶ {head} is a dict, keys: {items.keys()}")
        #         for sub_key, val_dict in items.items():
        #             line = f"    {sub_key}: "
        #             for metric_name, val_list in val_dict.items():
        #                 max_entries = 5 if len(val_list) > 5 else len(val_list)  # é˜²æ­¢ print æ—¶å‡ºé”™
        #                 preview = val_list[-max_entries:] if isinstance(val_list, list) else val_list
        #                 line += f"{metric_name}={preview}  "
        #             print(line)
        #     else:
        #         preview = items[-max_entries:] if isinstance(items, list) else items
        #         print(f"  â–¶ {head}: {preview}, len={len(items)}")
        # print("\n")

        # # === Print selg.log_data Metrics ===
        # # print(f"\n --------- self.log_data[{prefix}{text}] keys: ", self.log_data.keys())
        # print(f"\n --------- self.log_data[{prefix}{text}][metrics] keys: ", self.log_data[prefix+text]['metrics'].keys())
        # for key, val in self.log_data[prefix+text]['metrics'].items():
        #     if isinstance(val, dict):
        #         print(f" ---- {key}: len={len(val)}, keys: {val.keys()}")
        #         for sub_key, sub_val in val.items():
        #             if isinstance(sub_val, dict):
        #                 print(f"  {sub_key}: len={len(sub_val)}, keys: {sub_val.keys()}")
        #                 for sub_sub_key, sub_sub_val in sub_val.items():
        #                     print(f"   {sub_sub_key}: len={len(sub_sub_val)}, values: {sub_sub_val}")
        #             if isinstance(sub_val, list):
        #                 print(f"  {sub_key}: len={len(sub_val)}")
        #                 for i, sub_sub_val in enumerate(sub_val):
        #                     print(f"   {i}: {sub_sub_val}")
        #             else:
        #                 print(f"  {sub_key}: values: {sub_val}")
        #     else:
        #         print(f" ---- {key}: values: {val}")
        # print("\n")

        # === Log Metrics ===
        for head_key, collection in metric_collections.items():
            if not hasattr(collection, "compute"):
                continue  # skip non-MetricCollection objects

            computed_metrics = collection.compute()  # dict: {metric_name: value}

            for metric_name, metric_val in computed_metrics.items():
                # class-wise: list/tuple/tensor with shape [num_classes]
                # print(f"\n ------- ðŸ”· {prefix}{text} metric_collections[{head_key}][{metric_name}]: {metric_val}")

                if isinstance(metric_val, (list, tuple)):
                    values = metric_val
                elif isinstance(metric_val, torch.Tensor) and metric_val.ndim == 1:
                    values = metric_val.tolist()
                else:
                    values = [metric_val.item()]  # scalar

                if metric_name in ["iou_classwise", "dice_classwise"]:
                    for cls_idx, val in enumerate(values):
                        # skip background (class 0)
                        if cls_idx == 0:
                            continue
                        key = f"{metric_name.split('_')[0]}_class_{cls_idx}"
                        try:
                            if head_key in self.log_data[f"{prefix}{text}"]["metrics"]:
                                if head_key not in self.log_data[f"{prefix}{text}"]["metrics"]:
                                    self.log_data[f"{prefix}{text}"]["metrics"][head_key] = {head_key: {}}
                                if head_key not in self.log_data[f"{prefix}{text}"]["metrics"][head_key]:
                                    self.log_data[f"{prefix}{text}"]["metrics"][head_key][head_key] = {}
                                if key not in self.log_data[f"{prefix}{text}"]["metrics"][head_key][head_key]:
                                    self.log_data[f"{prefix}{text}"]["metrics"][head_key][head_key][key] = []

                                self.log(f"{prefix}{text}/metrics/{head_key}/{head_key}/{key}", val,
                                        on_step=on_step, on_epoch=on_epoch, prog_bar=False, batch_size=self.batch_size)
                                self.log_data[f"{prefix}{text}"]["metrics"][head_key][head_key][key].append(val)
                        except KeyError as e:
                            raise KeyError(f"[safe_log_metrics] Missing entry for {head_key}/{key}: {e}")

                        # try:
                        #     if head_key in ["bin", "tp", "hv"]:
                        #         self.log(f"{prefix}{text}/metrics/{head_key}/{head_key}/{key}", val,
                        #                 on_step=on_step, on_epoch=on_epoch, prog_bar=False, batch_size=self.batch_size)
                        #         self.log_data[f"{prefix}{text}"]["metrics"][head_key][head_key][key].append(val)
                        #     elif head_key == "boundary":
                        #         self.log(f"{prefix}{text}/metrics/boundary/{key}", val,
                        #                 on_step=on_step, on_epoch=on_epoch, prog_bar=False, batch_size=self.batch_size)
                        #         self.log_data[f"{prefix}{text}"]["metrics"]["boundary"][key].append(val)
                        # except KeyError:
                        #     raise KeyError(f"Missing entry for [{prefix}][metrics][{head_key}][...][{key}]")
                else:
                    # normal metric
                    val = values[0]
                    try:
                        if head_key in self.log_data[f"{prefix}{text}"]["metrics"]:
                            if head_key == "boundary":
                                if metric_name not in self.log_data[f"{prefix}{text}"]["metrics"][head_key]:
                                    self.log_data[f"{prefix}{text}"]["metrics"][head_key][metric_name] = []
                                self.log(f"{prefix}{text}/metrics/{head_key}/{metric_name}", val,
                                        on_step=on_step, on_epoch=on_epoch, prog_bar=False, batch_size=self.batch_size)
                                self.log_data[f"{prefix}{text}"]["metrics"][head_key][metric_name].append(val)
                            else:
                                if metric_name not in self.log_data[f"{prefix}{text}"]["metrics"][head_key][head_key]:
                                    self.log_data[f"{prefix}{text}"]["metrics"][head_key][head_key][metric_name] = []
                                self.log(f"{prefix}{text}/metrics/{head_key}/{head_key}/{metric_name}", val,
                                        on_step=on_step, on_epoch=on_epoch, prog_bar=False, batch_size=self.batch_size)
                                self.log_data[f"{prefix}{text}"]["metrics"][head_key][head_key][metric_name].append(val)
                    except KeyError as e:
                        raise KeyError(f"[safe_log_metrics] Missing entry for {head_key}/{metric_name}: {e}")
                
                    # try:
                    #     if head_key in ["bin", "tp", "hv"]:
                    #         self.log(f"{prefix}{text}/metrics/{head_key}/{head_key}/{metric_name}", val,
                    #                 on_step=on_step, on_epoch=on_epoch, prog_bar=False, batch_size=self.batch_size)
                    #         self.log_data[f"{prefix}{text}"]["metrics"][head_key][head_key][metric_name].append(val)
                    #     elif head_key == "boundary":
                    #         self.log(f"{prefix}{text}/metrics/boundary/{metric_name}", val,
                    #                 on_step=on_step, on_epoch=on_epoch, prog_bar=False, batch_size=self.batch_size)
                    #         self.log_data[f"{prefix}{text}"]["metrics"]["boundary"][metric_name].append(val)
                    # except KeyError:
                    #     raise KeyError(f"Missing entry for [{prefix}][metrics][{head_key}][...][{metric_name}]")
            
    def print_log_data(log_data, mode="train", epoch=True, max_entries=3):
        """
        Pretty-print key parts of log_data for quick inspection.

        Args:
            log_data (dict): The full log_data dictionary.
            mode (str): One of 'train', 'valid', 'test' to select mode.
            epoch (bool): Whether to print the '_epoch' version (recommended).
            max_entries (int): Number of recent entries to display per field.
        """
        key = f"{mode}_epoch" if epoch else mode
        data = log_data.get(key, {})

        print(f"\nðŸ“Œ === Log Summary: {key} ===")

        # === Losses ===
        print("\nðŸ”» Losses:")
        losses = data.get("losses", {})
        for head, items in losses.items():
            if isinstance(items, dict):
                print(f"  â–¶ {head}:")
                for sub_key, vals in items.items():
                    if isinstance(vals, dict):  # e.g., dice/bce/focal breakdown
                        line = f"    {sub_key}: "
                        for metric_name, val_list in vals.items():
                            preview = val_list[-max_entries:] if isinstance(val_list, list) else val_list
                            line += f"{metric_name}={preview}  "
                        print(line)
                    else:
                        preview = vals[-max_entries:] if isinstance(vals, list) else vals
                        print(f"    {sub_key}: {preview}")
            else:
                preview = items[-max_entries:] if isinstance(items, list) else items
                print(f"  â–¶ {head}: {preview}")

        # === Metrics ===
        print("\nðŸ”· Metrics:")
        metrics = data.get("metrics", {})
        for head, items in metrics.items():
            if isinstance(items, dict):
                print(f"  â–¶ {head}:")
                for sub_key, val_dict in items.items():
                    line = f"    {sub_key}: "
                    for metric_name, val_list in val_dict.items():
                        preview = val_list[-max_entries:] if isinstance(val_list, list) else val_list
                        line += f"{metric_name}={preview}  "
                    print(line)
            else:
                preview = items[-max_entries:] if isinstance(items, list) else items
                print(f"  â–¶ {head}: {preview}")

        print("âœ… Done.\n")
    
    def sanitize_output(self, output_dict):
        def clean_tensor(t):
            if torch.is_tensor(t):
                t = t.clone()
                t[torch.isnan(t)] = 0.0
                t[torch.isinf(t)] = 0.0
            return t

        for key, val in output_dict.items():
            if isinstance(val, torch.Tensor):
                output_dict[key] = clean_tensor(val)
            elif isinstance(val, list):
                output_dict[key] = [clean_tensor(v) for v in val]
            elif isinstance(val, dict):
                output_dict[key] = self.sanitize_output(val)
        return output_dict

    def training_step(self, batch, batch_idx):
        input_dict, patch_id = batch
        # input_dict = {
        #     'image': image,
        #     'bin': bin_map,
        #     'boundary': boundary_map,
        #     'inst': inst_map,
        #     'hv': hv_map,
        #     'tp': type_map,
        #     'bin_aux_outs': bin_aux_outs,
        #     'hv_aux_outs': hv_aux_outs,
        #     'type_aux_outs': type_aux_outs,
        # }

        if DEBUG:
            print(f"\n ====== training_step()")
            print(f" ====== Training step {batch_idx}, Patch ID: {patch_id}")
            self.print_dict(input_dict)
        
        # =========== Forward pass
        output_dict = self(input_dict["image"])
        if DEBUG:
            print("\n ====== Forward pass complete, output_dict: ")
            self.print_dict(output_dict)

        output_dict = self.sanitize_output(output_dict)
        if DEBUG:
            print("\n ====== sanitize_output dict: ")
            self.print_dict(output_dict)
        
        # compute loss
        with torch.autograd.set_detect_anomaly(True):
            losses = self.loss(output_dict, input_dict, ignored_masks=None)
        
        # Log all individual loss components
        self.log_losses(losses, prefix="train")
        # for key, value in loss_dict.items():
        #     if isinstance(value, dict):
        #         self.log_losses(value, prefix=f"{prefix}/{key}", on_step=on_step, on_epoch=on_epoch)
        #     elif isinstance(value, (float, int, torch.Tensor)):
        #         if isinstance(value, torch.Tensor):
        #             value = value.detach()
        #         self.log(f"{prefix}/{key}", value, on_step=on_step, on_epoch=on_epoch, prog_bar=False, batch_size=self.batch_size)
        

        # log losses
        self.log(f"train_loss", losses["total_loss"], on_epoch=True, prog_bar=True, batch_size=self.batch_size)

        #  æ¯ N æ­¥æ‰§è¡Œä¸€æ¬¡ step-level compute + log
        if (batch_idx + 1) % self.log_frequency == 0:
            # log losses
            self.safe_log_losses(losses, "train", on_step=True, on_epoch=False)
            # è®°å½•åˆ°TensorBoard
            self.log_to_tensorboard(losses, prefix="train", step=self.global_step)
        
        # # è®¡ç®— metrics
        # output_onehots = self.predict_mask_process(output_dict)
        # if DEBUG:
        #     print("\n ====== output_onehots dict: ")
        #     self.print_dict(output_dict)
        
        # gts_onehots = self.gts_mask_process(input_dict)
        # if DEBUG:
        #     print("\n ====== gts_onehots dict: ")
        #     self.print_dict(gts_onehots)
        # self.update_metrics(self.train_metrics, output_onehots, gts_onehots)
        # self.safe_log_metrics(self.train_metrics, "train", on_step=True, on_epoch=False)

        #  Visualization the input and output of the model every 200 steps
        output_masks = None
        gts_masks = None
        if (batch_idx + 1) % self.image_log_frequency == 0:
            try:
                # èŽ·å–é¢„æµ‹ç»“æžœ
                output_masks = self.predict_mask_process(output_dict)
                gts_masks = self.gts_mask_process(input_dict)
                
                # ä½¿ç”¨æ–°çš„å¯è§†åŒ–æ–¹æ³•
                images = input_dict["image"]
                
                # ä¿å­˜å›¾åƒåˆ°TensorBoardå’Œæ–‡ä»¶å¤¹
                self.log_images_to_tensorboard(images, output_masks, gts_masks, 
                                             prefix="train", step=self.global_step)
                
                print(f"âœ… Saved training visualization at step {batch_idx}, epoch {self.current_epoch}")
                
                del output_masks, gts_masks
                torch.cuda.empty_cache()

            except Exception as e:
                print(f"âŒ Error saving training visualization: {e}")
                import traceback
                traceback.print_exc()

        # ä¿å­˜æœ€åŽä¸€ä¸ªbatchçš„æ•°æ®ç”¨äºŽepochç»“æŸæ—¶çš„å›¾åƒè®°å½•
        self.last_train_batch = (input_dict, patch_id)
        
        # ä¼˜åŒ–æ—¥å¿—ä¿å­˜é¢‘çŽ‡ï¼šåªåœ¨ç‰¹å®šé—´éš”æˆ–epochç»“æŸæ—¶ä¿å­˜
        self.log_buffer_size += 1
        if (self.log_buffer_size % self.save_log_frequency == 0) or (batch_idx == 0):
            self._save_log()        # æŒä¹…åŒ–ä¿å­˜ log_data
        
        # å†…å­˜ç®¡ç† - æ¸…ç†æ‰€æœ‰å˜é‡
        del input_dict, output_dict
        torch.cuda.empty_cache()

        return losses['total_loss']       


    def on_train_start(self):
        print("\n Available metrics:")
        print(" Training metrics:", self.trainer.callback_metrics.keys())
    
    def on_train_epoch_end(self):
        # åˆ†é˜¶æ®µè®­ç»ƒï¼šåœ¨æŒ‡å®šepoché‡Šæ”¾æ‰€æœ‰å‚æ•°
        if (self.unfreeze_epoch is not None and 
            self.current_epoch >= self.unfreeze_epoch and 
            not self.parameters_unfrozen):
            
            print(f"\nðŸ”„ Epoch {self.current_epoch}: Unfreezing all parameters for full parameter training...")
            if hasattr(self.model, 'unfreeze_all_parameters'):
                self.model.unfreeze_all_parameters()
                self.parameters_unfrozen = True
                print(f"âœ… All parameters unfrozen at epoch {self.current_epoch}")
            else:
                print(f"âš ï¸ Model does not support unfreeze_all_parameters method")
        
        prefix = "train"
        # æ›´æ–° epoch åºå·
        if self.current_epoch not in self.log_data[prefix]["epochs"]:
            self.log_data[prefix].setdefault("epochs", []).append(self.current_epoch)

        # å›¾åƒè®°å½•çŽ°åœ¨åœ¨training_stepä¸­æ¯200æ­¥è¿›è¡Œï¼Œä¸å†åœ¨epochç»“æŸæ—¶è®°å½•
        # è¿™æ ·å¯ä»¥æ›´é¢‘ç¹åœ°ç›‘æŽ§è®­ç»ƒè¿‡ç¨‹ï¼Œç‰¹åˆ«æ˜¯åœ¨é•¿epochçš„æƒ…å†µä¸‹

        # æŒä¹…åŒ–ä¿å­˜ log_data
        self._save_log()

        if DEBUG:
            print(f"\n\n ====== {prefix}:{self.current_epoch} complete, log_data updated")
            self.print_log_data(self.log_data, mode="train", epoch=True)
            print(f"\n\n")
    
    def validation_step(self, batch, batch_idx, dataloader_idx=0):
        prefix = get_prefix_from_val_id(dataloader_idx)
        input_dict, patch_id = batch
        # input_dict = {
        #     'image': image,
        #     'bin': bin_map,
        #     'boundary': boundary_map,
        #     'inst': inst_map,
        #     'hv': hv_map,
        #     'tp': type_map,
        #     'bin_aux_outs': bin_aux_outs,
        #     'hv_aux_outs': hv_aux_outs,
        #     'type_aux_outs': type_aux_outs,
        # }

        if DEBUG:
            print(f"\n ====== validation_step()")
            print(f" ====== Validation step {batch_idx}, Patch ID: {patch_id}")
            self.print_dict(input_dict)

        # 2. å‰å‘æŽ¨ç†
        output_dict = self(input_dict["image"])

        if DEBUG:
            print("\n ====== Forward pass complete, output_dict: ")
            self.print_dict(output_dict)

        # # 3. æ¸…é™¤ nan å€¼
        # for head in gt_masks:
        #     if torch.isnan(gt_masks[head]).any():
        #         print(f"[WARN] NaN in val_gt {head}, patch_id: {patch_id}")
        #         gt_masks[head][torch.isnan(gt_masks[head])] = 0
        
        # 4. è®¡ç®—æŸå¤±
        losses = self.loss(output_dict, input_dict, ignored_masks=None)

        # Log all individual loss components
        self.log_losses(losses, prefix=prefix)
        # for key, value in loss_dict.items():
        #     if isinstance(value, dict):
        #         self.log_losses(value, prefix=f"{prefix}/{key}", on_step=on_step, on_epoch=on_epoch)
        #     elif isinstance(value, (float, int, torch.Tensor)):
        #         if isinstance(value, torch.Tensor):
        #             value = value.detach()
        #         self.log(f"{prefix}/{key}", value, on_step=on_step, on_epoch=on_epoch, prog_bar=False, batch_size=self.batch_size)
        
        # log losses
        self.log(f"val_loss", losses["total_loss"], on_epoch=True, prog_bar=True, batch_size=self.batch_size)

        # 5. æž„é€ é¢„æµ‹å’Œone-hotæ ‡ç­¾
        preds_onehots = self.predict_mask_process(output_dict)
        if DEBUG:
            print("\n ====== Predictions generated, preds_onehots: ")
            self.print_dict(preds_onehots)

        # 6. æž„é€ GT one-hotæ ‡ç­¾
        gts_onehots = self.gts_mask_process(input_dict)
        if DEBUG:
            print(f"\n ====== Validation_step(), GT datas: ")
            self.print_dict(input_dict)

        # Compute metrics
        self.update_metrics(self.valid_metrics[dataloader_idx], preds_onehots, gts_onehots)

        # 7. è®°å½•å­¦ä¹ çŽ‡ï¼ˆå½“å‰ optimizerï¼‰
        self.log(f"{prefix}/lr", self.lr, on_step=True, on_epoch=False)

        # æ¯ N æ­¥æ‰§è¡Œä¸€æ¬¡ step-level compute + log
        if (batch_idx + 1) % self.log_frequency == 0:
            self.safe_log_losses(losses, "valid", on_step=True, on_epoch=False)
            self.safe_log_metrics(self.valid_metrics[dataloader_idx], "valid", on_step=True, on_epoch=False)
            # è®°å½•åˆ°TensorBoard
            self.log_to_tensorboard(losses, self.valid_metrics[dataloader_idx], prefix=prefix, step=self.global_step)

        #  Visualization every 200 steps for validation
        if (batch_idx + 1) % self.image_log_frequency == 0:
            try:
                # ä½¿ç”¨æ–°çš„å¯è§†åŒ–æ–¹æ³•
                images = input_dict["image"]
                
                # ä¿å­˜å›¾åƒåˆ°TensorBoardå’Œæ–‡ä»¶å¤¹
                self.log_images_to_tensorboard(images, preds_onehots, gts_onehots, 
                                             prefix=prefix, step=self.global_step)
                
                print(f"âœ… Saved {prefix} visualization at step {batch_idx}, epoch {self.current_epoch}")
                
            except Exception as e:
                print(f"âŒ Error saving {prefix} visualization: {e}")
                import traceback
                traceback.print_exc()

        # ä¿å­˜æœ€åŽä¸€ä¸ªéªŒè¯batchçš„æ•°æ®ç”¨äºŽepochç»“æŸæ—¶çš„å›¾åƒè®°å½•
        self.last_valid_batch = (input_dict, patch_id)
        
        # éªŒè¯æ­¥éª¤ä¸é¢‘ç¹ä¿å­˜æ—¥å¿—ï¼Œåªåœ¨epochç»“æŸæ—¶ä¿å­˜
        # å†…å­˜ç®¡ç†
        del input_dict, output_dict, preds_onehots, gts_onehots
        torch.cuda.empty_cache()

        return losses["total_loss"]
    
    def on_validation_epoch_end(self, dataloader_idx=0):
        if self.trainer.sanity_checking:
            return

        if DEBUG:
            print(f"\n\n ====== on_validation_epoch_end() dataloader_idx: {dataloader_idx}")
            print(f" ======  self.valid_metrics: {self.valid_metrics}")

        for dataloader_idx, metric in enumerate(self.valid_metrics):
            prefix = get_prefix_from_val_id(dataloader_idx)
            
            # æ›´æ–° epoch åºå·
            if self.current_epoch not in self.log_data[prefix]["epochs"]:
                self.log_data[prefix].setdefault("epochs", []).append(self.current_epoch)

            # éªŒè¯é›†å›¾åƒè®°å½•çŽ°åœ¨åœ¨validation_stepä¸­æ¯200æ­¥è¿›è¡Œï¼Œä¸å†åœ¨epochç»“æŸæ—¶è®°å½•
            # è¿™æ ·å¯ä»¥æ›´é¢‘ç¹åœ°ç›‘æŽ§éªŒè¯è¿‡ç¨‹

            # éªŒè¯epochç»“æŸæ—¶ä¿å­˜æ—¥å¿—
            self._save_log()

        if DEBUG:
            print(f"\n\n ====== {prefix}:{self.current_epoch} complete, log_data updated")
            self.print_log_data(self.log_data, mode="valid", epoch=True)
            print(f"\n\n")

    def configure_optimizers(self):
        # åˆ†ç¦» adapter ä¸Žå…¶ä»–æ¨¡å—
        adapter_params = [p for n, p in self.named_parameters() if p.requires_grad and 'prompt_generator' in n]
        other_params = [p for n, p in self.named_parameters() if p.requires_grad and 'prompt_generator' not in n]

        opt = torch.optim.AdamW([
            {'params': adapter_params, 'lr': self.lr * 2},        # æ›´å¿«é€‚é…ä»»åŠ¡
            {'params': other_params, 'lr': self.lr}               # decoder ç­‰å¸¸è§„æ¨¡å—
        ], weight_decay=self.weight_decay)

        def lr_lambda(step):
            if step < self.warmup_steps: return step / self.warmup_steps
            if step < self.lr_steps[0]: return 1.0
            if step < self.lr_steps[1]: return 0.1
            return 0.01

        sched = torch.optim.lr_scheduler.LambdaLR(opt, lr_lambda, verbose=False)
        return {
            'optimizer': opt,
            'lr_scheduler': {
                'scheduler': sched,
                'interval': 'step'
            }
        }
    
    def on_train_end(self):
        """è®­ç»ƒç»“æŸæ—¶å…³é—­TensorBoard writer"""
        # æ˜¾ç¤ºæ€§èƒ½ç»Ÿè®¡
        self._log_performance_stats()
        
        # å¼ºåˆ¶ä¿å­˜æœ€ç»ˆæ—¥å¿—
        self._force_save_log()
        
        if hasattr(self, 'writer'):
            self.writer.close()
            # print(f"TensorBoard logs saved to: {self.tensorboard_dir}")
    
    def on_validation_end(self):
        """éªŒè¯ç»“æŸæ—¶å…³é—­TensorBoard writer"""
        if hasattr(self, 'writer'):
            self.writer.close()
            # print(f"TensorBoard logs saved to: {self.tensorboard_dir}")

